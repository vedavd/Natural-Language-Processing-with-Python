{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T8-1-Keras Part 1 & 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QfTI2AOkybr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDyYMjFMlDCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import inbuilt iris dataset\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsXgfZsalKDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris=load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnhHIU2glzlQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc158359-485b-4032-8f00-6986ac48f3c9"
      },
      "source": [
        "type(iris)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESiFZMpAl2Os",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf360413-061b-490d-958b-d808d1b4c529"
      },
      "source": [
        "#Print the description of the dataset\n",
        "print(iris.DESCR)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1ix_zFNl9xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X=iris.data\n",
        "#This is a numpy array with four columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeeTREHi5tBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02e111b4-b87e-4d80-94f8-36825a5c20cc"
      },
      "source": [
        "X"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TOcZhpU5tnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The above four columns are \n",
        "####sepal length in cm\n",
        "####sepal width in cm\n",
        "####petal length in cm\n",
        "####petal width in cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3DC6SCg6I5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let us create the target vazriable\n",
        "y=iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R77pILFc6NVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "9d077109-1095-418a-8020-6d9778f4917b"
      },
      "source": [
        "y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhwQGLxO6Nt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The above represents class:\n",
        "#####- Iris-Setosa\n",
        "#####- Iris-Versicolour\n",
        "#####- Iris-Virginica\n",
        "#Now we perform one hot encoding on the y variable which is of categorical type\n",
        "#class 0---->[1,0,0]\n",
        "#class 1---->[0,1,0]\n",
        "#class 2---->[0,0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTcc0MjH6nS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "9cd77d16-758e-408c-dba3-40bd1ae683af"
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLUSYNr37DGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo4LZ2Bp7J9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4e54cc0-85c1-4c1e-c0f6-88858c916c7e"
      },
      "source": [
        "y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2u29-q87KfN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b391772-26dc-470b-fd17-8d6c144f7c04"
      },
      "source": [
        "#Check the shape of y\n",
        "y.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SNIHjk27NwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create train test split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-1Rl_q37tdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_YgCcPm-qBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "30a51141-1646-4acc-a695-52afdc7ec60f"
      },
      "source": [
        "#Check y_test\n",
        "y_test\n",
        "#Everything will be shuffled"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6dxdFLA-rwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In Neural Networks it is always better to scale or standardize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#This fits all the values between a range\n",
        "#It divides the values by the Max value so that everything falls between zero and one"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUk84cer_Ws-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "756ce41b-72b0-4e01-a0bc-5f94983bccf8"
      },
      "source": [
        "#Let us see a demonstration on dividing by the Max value\n",
        "np.array([5,10,15,20])/20"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.5 , 0.75, 1.  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBwBaVI1Drr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create object of MinMaxscaler\n",
        "scaler_object=MinMaxScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yxBALCQEFCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42df9f71-0bcd-408a-ebe8-d9297378cfc1"
      },
      "source": [
        "#We fit the MinMaxscaler object only to the training data\n",
        "scaler_object.fit(X_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lgaBJApEVtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We we create the scaled versions of our X Training Data\n",
        "scaled_X_train=scaler_object.transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbBjlBpRFyne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We we create the scaled versions of our X Test Data\n",
        "scaled_X_test=scaler_object.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGnUz1TRF4dr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee6f88ac-262b-444c-f411-854d34b9e499"
      },
      "source": [
        "#Take a look at scaled training X data\n",
        "scaled_X_train"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n",
              "       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n",
              "       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n",
              "       [1.        , 0.36363636, 1.        , 0.79166667],\n",
              "       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n",
              "       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n",
              "       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n",
              "       [0.20588235, 0.        , 0.42857143, 0.375     ],\n",
              "       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n",
              "       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n",
              "       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n",
              "       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n",
              "       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n",
              "       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n",
              "       [1.        , 0.81818182, 1.        , 0.875     ],\n",
              "       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n",
              "       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n",
              "       [0.35294118, 1.        , 0.05357143, 0.04166667],\n",
              "       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n",
              "       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n",
              "       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n",
              "       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n",
              "       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n",
              "       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n",
              "       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n",
              "       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n",
              "       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n",
              "       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n",
              "       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n",
              "       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n",
              "       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n",
              "       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n",
              "       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n",
              "       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n",
              "       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n",
              "       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n",
              "       [1.        , 0.45454545, 0.89285714, 0.91666667],\n",
              "       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n",
              "       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n",
              "       [0.        , 0.45454545, 0.        , 0.        ],\n",
              "       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n",
              "       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n",
              "       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n",
              "       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n",
              "       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n",
              "       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n",
              "       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n",
              "       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n",
              "       [0.58823529, 0.59090909, 0.875     , 1.        ],\n",
              "       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n",
              "       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n",
              "       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n",
              "       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n",
              "       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n",
              "       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n",
              "       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n",
              "       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n",
              "       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n",
              "       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n",
              "       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n",
              "       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n",
              "       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n",
              "       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n",
              "       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n",
              "       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n",
              "       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n",
              "       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n",
              "       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n",
              "       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n",
              "       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n",
              "       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n",
              "       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n",
              "       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n",
              "       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n",
              "       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n",
              "       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n",
              "       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n",
              "       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n",
              "       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n",
              "       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n",
              "       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n",
              "       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n",
              "       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n",
              "       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n",
              "       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n",
              "       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1aU3GHFGCa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "898e72a3-49ec-4ba5-ee08-acfdbcae07d9"
      },
      "source": [
        "#Take a look at scaled test X data\n",
        "scaled_X_test"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.52941176,  0.36363636,  0.64285714,  0.45833333],\n",
              "       [ 0.41176471,  0.81818182,  0.10714286,  0.08333333],\n",
              "       [ 1.        ,  0.27272727,  1.03571429,  0.91666667],\n",
              "       [ 0.5       ,  0.40909091,  0.60714286,  0.58333333],\n",
              "       [ 0.73529412,  0.36363636,  0.66071429,  0.54166667],\n",
              "       [ 0.32352941,  0.63636364,  0.07142857,  0.125     ],\n",
              "       [ 0.38235294,  0.40909091,  0.44642857,  0.5       ],\n",
              "       [ 0.76470588,  0.5       ,  0.71428571,  0.91666667],\n",
              "       [ 0.55882353,  0.09090909,  0.60714286,  0.58333333],\n",
              "       [ 0.44117647,  0.31818182,  0.5       ,  0.45833333],\n",
              "       [ 0.64705882,  0.54545455,  0.71428571,  0.79166667],\n",
              "       [ 0.14705882,  0.45454545,  0.05357143,  0.        ],\n",
              "       [ 0.35294118,  0.68181818,  0.03571429,  0.04166667],\n",
              "       [ 0.17647059,  0.5       ,  0.07142857,  0.        ],\n",
              "       [ 0.23529412,  0.81818182,  0.07142857,  0.08333333],\n",
              "       [ 0.58823529,  0.59090909,  0.64285714,  0.625     ],\n",
              "       [ 0.64705882,  0.45454545,  0.83928571,  0.875     ],\n",
              "       [ 0.38235294,  0.22727273,  0.5       ,  0.41666667],\n",
              "       [ 0.41176471,  0.36363636,  0.60714286,  0.5       ],\n",
              "       [ 0.61764706,  0.36363636,  0.80357143,  0.875     ],\n",
              "       [ 0.11764706,  0.54545455,  0.08928571,  0.04166667],\n",
              "       [ 0.52941176,  0.45454545,  0.67857143,  0.70833333],\n",
              "       [ 0.20588235,  0.63636364,  0.08928571,  0.125     ],\n",
              "       [ 0.61764706,  0.36363636,  0.80357143,  0.83333333],\n",
              "       [ 1.05882353,  0.81818182,  0.94642857,  0.79166667],\n",
              "       [ 0.70588235,  0.45454545,  0.73214286,  0.91666667],\n",
              "       [ 0.70588235,  0.22727273,  0.83928571,  0.70833333],\n",
              "       [ 0.73529412,  0.54545455,  0.85714286,  0.91666667],\n",
              "       [ 0.14705882,  0.45454545,  0.05357143,  0.08333333],\n",
              "       [ 0.14705882,  0.5       ,  0.08928571,  0.04166667],\n",
              "       [ 0.08823529,  0.72727273, -0.01785714,  0.04166667],\n",
              "       [ 0.41176471,  1.09090909,  0.07142857,  0.125     ],\n",
              "       [ 0.70588235,  0.5       ,  0.58928571,  0.54166667],\n",
              "       [ 0.14705882,  0.63636364,  0.08928571,  0.04166667],\n",
              "       [ 0.02941176,  0.54545455,  0.03571429,  0.04166667],\n",
              "       [ 0.58823529,  0.22727273,  0.69642857,  0.75      ],\n",
              "       [ 0.61764706,  0.54545455,  0.60714286,  0.58333333],\n",
              "       [ 0.26470588,  0.68181818,  0.07142857,  0.04166667],\n",
              "       [ 0.20588235,  0.72727273,  0.05357143,  0.04166667],\n",
              "       [ 0.26470588,  0.95454545,  0.07142857,  0.        ],\n",
              "       [ 0.44117647,  0.31818182,  0.71428571,  0.75      ],\n",
              "       [ 0.5       ,  0.63636364,  0.60714286,  0.625     ],\n",
              "       [ 0.70588235,  0.5       ,  0.64285714,  0.58333333],\n",
              "       [ 0.32352941,  0.86363636,  0.03571429,  0.125     ],\n",
              "       [ 0.32352941,  0.77272727,  0.07142857,  0.04166667],\n",
              "       [ 0.35294118,  0.18181818,  0.46428571,  0.375     ],\n",
              "       [ 0.58823529,  0.36363636,  0.71428571,  0.58333333],\n",
              "       [ 0.61764706,  0.5       ,  0.78571429,  0.70833333],\n",
              "       [ 0.67647059,  0.45454545,  0.58928571,  0.54166667],\n",
              "       [ 0.85294118,  0.72727273,  0.89285714,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRhZLCnXGKIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build the Neural Network\n",
        "#The below builds model with essentially sequence of layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKzTICH-HQC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "3acfc307-28cb-48e1-9cb6-407b60b4fa99"
      },
      "source": [
        "#We first cresate the Sequential Model and then try adding layers to it\n",
        "model=Sequential()\n",
        "model.add(Dense(8,input_dim=4,activation='relu'))\n",
        "#units-refer to the number of neurons that go into this layer\n",
        "#Here we are using 8. We are using double the number of features\n",
        "#As of now we have no clue whether or not that number is correct or not\n",
        "#Domain Knowledge is essential to get an idea on that number\n",
        "#what should the activation function be\n",
        "#input_dim=4 because we have four columns in the X\n",
        "#Add another dense layer\n",
        "model.add(Dense(8,input_dim=4,activation='relu'))\n",
        "\n",
        "#Add the output layer\n",
        "#We are going to have 3 neurons and that will have Soft Max activation\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "#Each neuron is going to have probability for belonging to a particular class\n",
        "#Which is why we perform onehot encoded\n",
        "#At the end Neurons might return % as an output that represents chance for each index position\n",
        "#The above will give an output something like this [0.2,0.3,0.5]\n",
        "#Compile\n",
        "#the loss selction depends on actually what we are performing\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnn-wTvEc0fa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fbe3101d-4866-426f-ac5f-d55f235b2a3f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn-CsPNPdiid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6059830-103e-4f90-98c9-c074a5deb391"
      },
      "source": [
        "#Fit the above model to scaledX_train_data\n",
        "#We don't need to scale y_train as they are already zeroes and ones\n",
        "model.fit(scaled_X_train,y_train,epochs=150,verbose=2)\n",
        "#one epoch is running thorigh the entire dataset\n",
        "#Let us run for 150 epochs\n",
        "#verbose is basically how much output you want information\n",
        "#If verbose=0 you will not get anything reporting\n",
        "#If verbose=1 it will show a progress bar\n",
        "#If verbose=2 it will show how much loss, what is current accuracy"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 0s - loss: 1.1356 - acc: 0.3100\n",
            "Epoch 2/150\n",
            " - 0s - loss: 1.1284 - acc: 0.3100\n",
            "Epoch 3/150\n",
            " - 0s - loss: 1.1217 - acc: 0.3100\n",
            "Epoch 4/150\n",
            " - 0s - loss: 1.1164 - acc: 0.3100\n",
            "Epoch 5/150\n",
            " - 0s - loss: 1.1103 - acc: 0.3100\n",
            "Epoch 6/150\n",
            " - 0s - loss: 1.1064 - acc: 0.3100\n",
            "Epoch 7/150\n",
            " - 0s - loss: 1.1005 - acc: 0.3400\n",
            "Epoch 8/150\n",
            " - 0s - loss: 1.0958 - acc: 0.3700\n",
            "Epoch 9/150\n",
            " - 0s - loss: 1.0911 - acc: 0.4100\n",
            "Epoch 10/150\n",
            " - 0s - loss: 1.0872 - acc: 0.5100\n",
            "Epoch 11/150\n",
            " - 0s - loss: 1.0828 - acc: 0.5900\n",
            "Epoch 12/150\n",
            " - 0s - loss: 1.0794 - acc: 0.6100\n",
            "Epoch 13/150\n",
            " - 0s - loss: 1.0762 - acc: 0.5900\n",
            "Epoch 14/150\n",
            " - 0s - loss: 1.0723 - acc: 0.5900\n",
            "Epoch 15/150\n",
            " - 0s - loss: 1.0688 - acc: 0.6100\n",
            "Epoch 16/150\n",
            " - 0s - loss: 1.0653 - acc: 0.6200\n",
            "Epoch 17/150\n",
            " - 0s - loss: 1.0615 - acc: 0.6200\n",
            "Epoch 18/150\n",
            " - 0s - loss: 1.0578 - acc: 0.6200\n",
            "Epoch 19/150\n",
            " - 0s - loss: 1.0539 - acc: 0.6200\n",
            "Epoch 20/150\n",
            " - 0s - loss: 1.0500 - acc: 0.6200\n",
            "Epoch 21/150\n",
            " - 0s - loss: 1.0460 - acc: 0.6400\n",
            "Epoch 22/150\n",
            " - 0s - loss: 1.0419 - acc: 0.6400\n",
            "Epoch 23/150\n",
            " - 0s - loss: 1.0376 - acc: 0.6400\n",
            "Epoch 24/150\n",
            " - 0s - loss: 1.0336 - acc: 0.6500\n",
            "Epoch 25/150\n",
            " - 0s - loss: 1.0293 - acc: 0.6700\n",
            "Epoch 26/150\n",
            " - 0s - loss: 1.0251 - acc: 0.6700\n",
            "Epoch 27/150\n",
            " - 0s - loss: 1.0203 - acc: 0.6700\n",
            "Epoch 28/150\n",
            " - 0s - loss: 1.0162 - acc: 0.6600\n",
            "Epoch 29/150\n",
            " - 0s - loss: 1.0115 - acc: 0.6600\n",
            "Epoch 30/150\n",
            " - 0s - loss: 1.0072 - acc: 0.6600\n",
            "Epoch 31/150\n",
            " - 0s - loss: 1.0026 - acc: 0.6700\n",
            "Epoch 32/150\n",
            " - 0s - loss: 0.9980 - acc: 0.6700\n",
            "Epoch 33/150\n",
            " - 0s - loss: 0.9938 - acc: 0.6800\n",
            "Epoch 34/150\n",
            " - 0s - loss: 0.9891 - acc: 0.6800\n",
            "Epoch 35/150\n",
            " - 0s - loss: 0.9842 - acc: 0.6800\n",
            "Epoch 36/150\n",
            " - 0s - loss: 0.9793 - acc: 0.6800\n",
            "Epoch 37/150\n",
            " - 0s - loss: 0.9744 - acc: 0.6800\n",
            "Epoch 38/150\n",
            " - 0s - loss: 0.9689 - acc: 0.6800\n",
            "Epoch 39/150\n",
            " - 0s - loss: 0.9637 - acc: 0.6900\n",
            "Epoch 40/150\n",
            " - 0s - loss: 0.9581 - acc: 0.6800\n",
            "Epoch 41/150\n",
            " - 0s - loss: 0.9527 - acc: 0.6600\n",
            "Epoch 42/150\n",
            " - 0s - loss: 0.9466 - acc: 0.6600\n",
            "Epoch 43/150\n",
            " - 0s - loss: 0.9409 - acc: 0.6600\n",
            "Epoch 44/150\n",
            " - 0s - loss: 0.9359 - acc: 0.6600\n",
            "Epoch 45/150\n",
            " - 0s - loss: 0.9302 - acc: 0.6600\n",
            "Epoch 46/150\n",
            " - 0s - loss: 0.9245 - acc: 0.6600\n",
            "Epoch 47/150\n",
            " - 0s - loss: 0.9185 - acc: 0.6600\n",
            "Epoch 48/150\n",
            " - 0s - loss: 0.9125 - acc: 0.6700\n",
            "Epoch 49/150\n",
            " - 0s - loss: 0.9062 - acc: 0.6700\n",
            "Epoch 50/150\n",
            " - 0s - loss: 0.9004 - acc: 0.6600\n",
            "Epoch 51/150\n",
            " - 0s - loss: 0.8941 - acc: 0.6600\n",
            "Epoch 52/150\n",
            " - 0s - loss: 0.8877 - acc: 0.6600\n",
            "Epoch 53/150\n",
            " - 0s - loss: 0.8814 - acc: 0.6600\n",
            "Epoch 54/150\n",
            " - 0s - loss: 0.8748 - acc: 0.6600\n",
            "Epoch 55/150\n",
            " - 0s - loss: 0.8678 - acc: 0.6700\n",
            "Epoch 56/150\n",
            " - 0s - loss: 0.8610 - acc: 0.6900\n",
            "Epoch 57/150\n",
            " - 0s - loss: 0.8536 - acc: 0.6900\n",
            "Epoch 58/150\n",
            " - 0s - loss: 0.8459 - acc: 0.7100\n",
            "Epoch 59/150\n",
            " - 0s - loss: 0.8387 - acc: 0.7200\n",
            "Epoch 60/150\n",
            " - 0s - loss: 0.8318 - acc: 0.7300\n",
            "Epoch 61/150\n",
            " - 0s - loss: 0.8245 - acc: 0.7300\n",
            "Epoch 62/150\n",
            " - 0s - loss: 0.8167 - acc: 0.7300\n",
            "Epoch 63/150\n",
            " - 0s - loss: 0.8086 - acc: 0.7200\n",
            "Epoch 64/150\n",
            " - 0s - loss: 0.8008 - acc: 0.7200\n",
            "Epoch 65/150\n",
            " - 0s - loss: 0.7932 - acc: 0.7200\n",
            "Epoch 66/150\n",
            " - 0s - loss: 0.7854 - acc: 0.7200\n",
            "Epoch 67/150\n",
            " - 0s - loss: 0.7780 - acc: 0.7200\n",
            "Epoch 68/150\n",
            " - 0s - loss: 0.7704 - acc: 0.7200\n",
            "Epoch 69/150\n",
            " - 0s - loss: 0.7622 - acc: 0.7200\n",
            "Epoch 70/150\n",
            " - 0s - loss: 0.7544 - acc: 0.7500\n",
            "Epoch 71/150\n",
            " - 0s - loss: 0.7465 - acc: 0.7500\n",
            "Epoch 72/150\n",
            " - 0s - loss: 0.7387 - acc: 0.7500\n",
            "Epoch 73/150\n",
            " - 0s - loss: 0.7305 - acc: 0.7400\n",
            "Epoch 74/150\n",
            " - 0s - loss: 0.7230 - acc: 0.7200\n",
            "Epoch 75/150\n",
            " - 0s - loss: 0.7156 - acc: 0.7200\n",
            "Epoch 76/150\n",
            " - 0s - loss: 0.7082 - acc: 0.7200\n",
            "Epoch 77/150\n",
            " - 0s - loss: 0.7007 - acc: 0.7200\n",
            "Epoch 78/150\n",
            " - 0s - loss: 0.6933 - acc: 0.7200\n",
            "Epoch 79/150\n",
            " - 0s - loss: 0.6856 - acc: 0.7400\n",
            "Epoch 80/150\n",
            " - 0s - loss: 0.6780 - acc: 0.7400\n",
            "Epoch 81/150\n",
            " - 0s - loss: 0.6702 - acc: 0.7600\n",
            "Epoch 82/150\n",
            " - 0s - loss: 0.6636 - acc: 0.7900\n",
            "Epoch 83/150\n",
            " - 0s - loss: 0.6568 - acc: 0.8100\n",
            "Epoch 84/150\n",
            " - 0s - loss: 0.6495 - acc: 0.8100\n",
            "Epoch 85/150\n",
            " - 0s - loss: 0.6425 - acc: 0.8100\n",
            "Epoch 86/150\n",
            " - 0s - loss: 0.6356 - acc: 0.8100\n",
            "Epoch 87/150\n",
            " - 0s - loss: 0.6290 - acc: 0.8200\n",
            "Epoch 88/150\n",
            " - 0s - loss: 0.6219 - acc: 0.8300\n",
            "Epoch 89/150\n",
            " - 0s - loss: 0.6161 - acc: 0.7700\n",
            "Epoch 90/150\n",
            " - 0s - loss: 0.6089 - acc: 0.7700\n",
            "Epoch 91/150\n",
            " - 0s - loss: 0.6033 - acc: 0.7600\n",
            "Epoch 92/150\n",
            " - 0s - loss: 0.5980 - acc: 0.7500\n",
            "Epoch 93/150\n",
            " - 0s - loss: 0.5918 - acc: 0.7600\n",
            "Epoch 94/150\n",
            " - 0s - loss: 0.5857 - acc: 0.7600\n",
            "Epoch 95/150\n",
            " - 0s - loss: 0.5801 - acc: 0.7700\n",
            "Epoch 96/150\n",
            " - 0s - loss: 0.5750 - acc: 0.7600\n",
            "Epoch 97/150\n",
            " - 0s - loss: 0.5695 - acc: 0.7700\n",
            "Epoch 98/150\n",
            " - 0s - loss: 0.5640 - acc: 0.7800\n",
            "Epoch 99/150\n",
            " - 0s - loss: 0.5589 - acc: 0.7900\n",
            "Epoch 100/150\n",
            " - 0s - loss: 0.5538 - acc: 0.8100\n",
            "Epoch 101/150\n",
            " - 0s - loss: 0.5489 - acc: 0.8000\n",
            "Epoch 102/150\n",
            " - 0s - loss: 0.5447 - acc: 0.8200\n",
            "Epoch 103/150\n",
            " - 0s - loss: 0.5397 - acc: 0.8400\n",
            "Epoch 104/150\n",
            " - 0s - loss: 0.5353 - acc: 0.8600\n",
            "Epoch 105/150\n",
            " - 0s - loss: 0.5307 - acc: 0.8600\n",
            "Epoch 106/150\n",
            " - 0s - loss: 0.5268 - acc: 0.8600\n",
            "Epoch 107/150\n",
            " - 0s - loss: 0.5217 - acc: 0.8600\n",
            "Epoch 108/150\n",
            " - 0s - loss: 0.5178 - acc: 0.8300\n",
            "Epoch 109/150\n",
            " - 0s - loss: 0.5160 - acc: 0.8100\n",
            "Epoch 110/150\n",
            " - 0s - loss: 0.5109 - acc: 0.8100\n",
            "Epoch 111/150\n",
            " - 0s - loss: 0.5065 - acc: 0.8200\n",
            "Epoch 112/150\n",
            " - 0s - loss: 0.5029 - acc: 0.8400\n",
            "Epoch 113/150\n",
            " - 0s - loss: 0.4994 - acc: 0.8600\n",
            "Epoch 114/150\n",
            " - 0s - loss: 0.4960 - acc: 0.8600\n",
            "Epoch 115/150\n",
            " - 0s - loss: 0.4927 - acc: 0.8600\n",
            "Epoch 116/150\n",
            " - 0s - loss: 0.4892 - acc: 0.8500\n",
            "Epoch 117/150\n",
            " - 0s - loss: 0.4859 - acc: 0.8500\n",
            "Epoch 118/150\n",
            " - 0s - loss: 0.4827 - acc: 0.8600\n",
            "Epoch 119/150\n",
            " - 0s - loss: 0.4797 - acc: 0.8500\n",
            "Epoch 120/150\n",
            " - 0s - loss: 0.4765 - acc: 0.8600\n",
            "Epoch 121/150\n",
            " - 0s - loss: 0.4729 - acc: 0.8600\n",
            "Epoch 122/150\n",
            " - 0s - loss: 0.4702 - acc: 0.8700\n",
            "Epoch 123/150\n",
            " - 0s - loss: 0.4668 - acc: 0.8800\n",
            "Epoch 124/150\n",
            " - 0s - loss: 0.4640 - acc: 0.8900\n",
            "Epoch 125/150\n",
            " - 0s - loss: 0.4609 - acc: 0.8700\n",
            "Epoch 126/150\n",
            " - 0s - loss: 0.4579 - acc: 0.8700\n",
            "Epoch 127/150\n",
            " - 0s - loss: 0.4552 - acc: 0.8700\n",
            "Epoch 128/150\n",
            " - 0s - loss: 0.4523 - acc: 0.8700\n",
            "Epoch 129/150\n",
            " - 0s - loss: 0.4493 - acc: 0.8700\n",
            "Epoch 130/150\n",
            " - 0s - loss: 0.4473 - acc: 0.8700\n",
            "Epoch 131/150\n",
            " - 0s - loss: 0.4443 - acc: 0.8700\n",
            "Epoch 132/150\n",
            " - 0s - loss: 0.4419 - acc: 0.8700\n",
            "Epoch 133/150\n",
            " - 0s - loss: 0.4389 - acc: 0.8700\n",
            "Epoch 134/150\n",
            " - 0s - loss: 0.4373 - acc: 0.8700\n",
            "Epoch 135/150\n",
            " - 0s - loss: 0.4342 - acc: 0.8700\n",
            "Epoch 136/150\n",
            " - 0s - loss: 0.4321 - acc: 0.8700\n",
            "Epoch 137/150\n",
            " - 0s - loss: 0.4293 - acc: 0.8900\n",
            "Epoch 138/150\n",
            " - 0s - loss: 0.4267 - acc: 0.8900\n",
            "Epoch 139/150\n",
            " - 0s - loss: 0.4243 - acc: 0.9200\n",
            "Epoch 140/150\n",
            " - 0s - loss: 0.4227 - acc: 0.9300\n",
            "Epoch 141/150\n",
            " - 0s - loss: 0.4205 - acc: 0.9300\n",
            "Epoch 142/150\n",
            " - 0s - loss: 0.4181 - acc: 0.9400\n",
            "Epoch 143/150\n",
            " - 0s - loss: 0.4157 - acc: 0.9300\n",
            "Epoch 144/150\n",
            " - 0s - loss: 0.4137 - acc: 0.9400\n",
            "Epoch 145/150\n",
            " - 0s - loss: 0.4117 - acc: 0.9400\n",
            "Epoch 146/150\n",
            " - 0s - loss: 0.4095 - acc: 0.9400\n",
            "Epoch 147/150\n",
            " - 0s - loss: 0.4083 - acc: 0.9300\n",
            "Epoch 148/150\n",
            " - 0s - loss: 0.4049 - acc: 0.9400\n",
            "Epoch 149/150\n",
            " - 0s - loss: 0.4021 - acc: 0.9500\n",
            "Epoch 150/150\n",
            " - 0s - loss: 0.3997 - acc: 0.9300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ad5850550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTWIueA7kQFd",
        "colab_type": "text"
      },
      "source": [
        "##Keras Part Two"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfKF1pnRkR6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "985d74a1-e754-4906-ee09-f9f97ff06705"
      },
      "source": [
        "#Now we need to scale the test data(we already did this as scaled_X_test) or the new incoming data\n",
        "#If you are giving a new value for testing that value should be scaled as our model is built for scaled values\n",
        "#Let us check the predictions of the scaled_X_test data\n",
        "model.predict(scaled_X_test)\n",
        "#This will give the probabilities as output\n",
        "#For example take the first row of output\n",
        "#0.02931215, 0.5161774 , 0.45451042\n",
        "#the probability of belonging to class zero  is 2.9%\n",
        "#the probability of belonging to class one  is 51.6%\n",
        "#the probability of belonging to class two  is 45.45%"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02931215, 0.5161774 , 0.45451042],\n",
              "       [0.9239819 , 0.06552058, 0.01049744],\n",
              "       [0.00150274, 0.2163753 , 0.782122  ],\n",
              "       [0.03699883, 0.48744926, 0.4755519 ],\n",
              "       [0.01278939, 0.4575539 , 0.5296567 ],\n",
              "       [0.8907346 , 0.09538307, 0.01388235],\n",
              "       [0.14644213, 0.5386306 , 0.3149273 ],\n",
              "       [0.00577309, 0.33105257, 0.66317433],\n",
              "       [0.02128422, 0.5244103 , 0.45430547],\n",
              "       [0.07086972, 0.57925016, 0.3498801 ],\n",
              "       [0.01357049, 0.35657257, 0.62985694],\n",
              "       [0.89608365, 0.09336475, 0.01055158],\n",
              "       [0.925289  , 0.06671976, 0.00799119],\n",
              "       [0.89878523, 0.09041295, 0.01080174],\n",
              "       [0.9588441 , 0.03556448, 0.00559133],\n",
              "       [0.04405726, 0.43383726, 0.52210546],\n",
              "       [0.00515486, 0.29160568, 0.70323944],\n",
              "       [0.06336904, 0.60201734, 0.3346136 ],\n",
              "       [0.04781337, 0.50911486, 0.4430718 ],\n",
              "       [0.00607957, 0.32466698, 0.66925347],\n",
              "       [0.91324306, 0.07610235, 0.01065463],\n",
              "       [0.02034908, 0.40557173, 0.57407916],\n",
              "       [0.9167493 , 0.07198525, 0.01126544],\n",
              "       [0.00680818, 0.3376541 , 0.6555377 ],\n",
              "       [0.00242987, 0.22261655, 0.77495354],\n",
              "       [0.00513208, 0.32241687, 0.6724511 ],\n",
              "       [0.00752242, 0.37613365, 0.616344  ],\n",
              "       [0.00362227, 0.26394507, 0.7324326 ],\n",
              "       [0.88451064, 0.10256066, 0.01292869],\n",
              "       [0.8933193 , 0.09412347, 0.01255725],\n",
              "       [0.96570486, 0.03043814, 0.00385698],\n",
              "       [0.97749114, 0.01913753, 0.00337138],\n",
              "       [0.03409386, 0.51534426, 0.4505619 ],\n",
              "       [0.93296665, 0.0585013 , 0.00853213],\n",
              "       [0.9317788 , 0.06028559, 0.00793562],\n",
              "       [0.01142138, 0.44793   , 0.5406486 ],\n",
              "       [0.04488034, 0.4755851 , 0.47953448],\n",
              "       [0.9328195 , 0.05923498, 0.00794551],\n",
              "       [0.95217687, 0.04203948, 0.00578356],\n",
              "       [0.97601557, 0.02082315, 0.00316129],\n",
              "       [0.01442776, 0.39374757, 0.59182465],\n",
              "       [0.08485187, 0.42794737, 0.4872007 ],\n",
              "       [0.02286126, 0.47299075, 0.50414807],\n",
              "       [0.96204364, 0.0330466 , 0.0049097 ],\n",
              "       [0.9447285 , 0.04858171, 0.00668976],\n",
              "       [0.07697739, 0.61971956, 0.30330312],\n",
              "       [0.01580552, 0.45112672, 0.53306776],\n",
              "       [0.00948965, 0.34415716, 0.64635324],\n",
              "       [0.03096848, 0.5201739 , 0.4488576 ],\n",
              "       [0.00281288, 0.20477612, 0.7924109 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBzDKKNTmFKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6131ff42-2657-4e84-a869-40ee4142ac45"
      },
      "source": [
        "#Let us predict the classes of X_test data \n",
        "model.predict_classes(scaled_X_test)\n",
        "#The output is not the one hot encoded values of the classes instead it prints the index position of the class\n",
        "#We are now suppossed to pcompare these results with y_test"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW3NUNy5m8lq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "4b953318-a773-432c-dd80-8329a2ef7c06"
      },
      "source": [
        " y_test"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld7107yvnVYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compare results with predictions\n",
        "predictions=model.predict_classes(scaled_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1llMPpAWoHyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "bb217300-f433-423f-c1f8-d3cba85c7ade"
      },
      "source": [
        "#We are going to transform our y_test\n",
        "y_test.argmax(axis=1)\n",
        "#This reprots back actual classes"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgD3Xn9TogeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Now the predictions and y_test are in the same format\n",
        " #Now we can compare\n",
        " from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaZxbLSopMic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7e722e2e-e978-42aa-a765-9eaeab31d6fb"
      },
      "source": [
        "confusion_matrix(y_test.argmax(axis=1),predictions)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19,  0,  0],\n",
              "       [ 0, 10,  5],\n",
              "       [ 0,  0, 16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw47P21jpWre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "336e1ad0-c1a2-4fa0-bf2a-5230e55c3aae"
      },
      "source": [
        "#Print the classification report\n",
        "print(classification_report(y_test.argmax(axis=1),predictions))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.67      0.80        15\n",
            "           2       0.76      1.00      0.86        16\n",
            "\n",
            "    accuracy                           0.90        50\n",
            "   macro avg       0.92      0.89      0.89        50\n",
            "weighted avg       0.92      0.90      0.90        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5slR1mKKpt65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7f10575-f27a-422c-cbd9-5042a480f51b"
      },
      "source": [
        "#Accuracy Score\n",
        "print(accuracy_score(y_test.argmax(axis=1),predictions))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLOCs6U0qBhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#models related to text generation can take hours unlike the 150 epochs above\n",
        "#We want to save and load our model\n",
        "#We save the model as below\n",
        "model.save('myfirstmodel.h5')\n",
        "#h5 is the extension\n",
        "#This saves all the weights of the network, so that we can quickly load it up again\n",
        "#This will be useful when you shut down the computer and want to continue working next day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTtXom9Gr6hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlrjx-ylr-bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model=load_model('myfirstmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16y1lBXksIjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "35a710c1-9616-4aee-a4c1-943246f0b834"
      },
      "source": [
        "#Be careful with the naming scheme as we do not want to overwrite a particular model\n",
        "#Now, I can use the new model similar to the old model\n",
        "new_model.predict_classes(scaled_X_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov9QPZFAshEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}